{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 32: Likelihood Ratio Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we introduced Likelihood Ratio tests. Recall that the point of a likelihood ratio test is to compare the likelihood function under a hypothesized value of the parameter with the liklihood function at its maximum. Instead of looking at the ratio $\\Lambda$ itself, we often consider $-2\\log \\Lambda$ instead, since it has a handy distribution. \n",
    "\n",
    "### Example 1: Exponential Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables from the exponential distribution with unknown parameter $\\lambda$. Recall that the maximum likelihood estimate of $\\lambda$ is $1\\over\\bar{X}$. We collect a random sample of size 20 and want to test the hypothesis $H_0: \\lambda = 3$ vs $H_1: \\lambda \\neq 3$. Using the data in the python box below, conduct a likelihood ratio test on this hypothesis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=np.array([0.18,0.277,0.105,0.126,0.225,0.026,0.123,0.423,0.006,0.281,0.050,0.692,0.105,0.275,0.346,0.079,0.045,0.222,0.063,0.281])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 5.089058524173028\n",
      "0.1965\n",
      "Test Statistic 4.719222360188461\n",
      "0.0298 <= 0.05, so we reject the null: lambda cannot be 3\n"
     ]
    }
   ],
   "source": [
    "avg = np.average(my_data)\n",
    "print(\"lambda =\",1/avg)\n",
    "print(avg)\n",
    "Lambda = ((3**20)*exp(-60*avg))/(((1/avg)**20)*exp(-20))\n",
    "test_statistic = -2*log(Lambda)\n",
    "print(\"Test Statistic\",test_statistic)\n",
    "p_value = 1-stats.chi2.cdf(test_statistic,1)\n",
    "print(p_value.round(4), \"<= 0.05, so we reject the null: lambda cannot be 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Suppose that the true value of $\\lambda$ is 5. Let's determine the power of this test. Let $n=20$. Then determine the power if $n=50$. Remember, power is the probability of correctly rejecting the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find what value of $-2 \\log \\Lambda$ would lead you to reject $H_0$. This is sometimes called the critical value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Value for the test statistic 3.84\n",
      "Check 0.050000000000000044 : close to 0.05?\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "#we reject anything with a p value under 0.05. so 1-stats.chi2.cdf(test_statistic,1) must equal 0.05 at the tipping point\n",
    "crit = 0\n",
    "for i in range(0,10000):\n",
    "    if 1-stats.chi2.cdf(i/100,1) >= 0.05:\n",
    "        crit = i/100\n",
    "print(\"Critical Value for the test statistic\",crit)\n",
    "print(\"Check\",1-stats.chi2.cdf(crit,1).round(4),\": close to 0.05?\")\n",
    "print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 5\n",
      "0.1965\n",
      "Test Statistic 0.006197409548836068\n",
      "p value 0.9372524516615959\n"
     ]
    }
   ],
   "source": [
    "avg = np.average(my_data)\n",
    "print(\"lambda = 5\")\n",
    "print(avg)\n",
    "Lambda = ((5**20)*exp(-100*avg))/(((1/avg)**20)*exp(-20))\n",
    "test_statistic = -2*log(Lambda)\n",
    "print(\"Test Statistic\",test_statistic)\n",
    "p_value = 1-stats.chi2.cdf(test_statistic,1)\n",
    "print(\"p value\",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, obtain the power. Obtain a sample of size 20 from the true population and obtain the value of $-2\\log \\Lambda$ for this sample. Repeat many times and determine how often you reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of times we (correctly) reject the null: 64.39 %\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "count = 0\n",
    "n=20\n",
    "#np.random.seed = 2020\n",
    "for i in range(iterations):\n",
    "    sample = np.random.choice(my_data,20)\n",
    "    avg = np.average(sample)\n",
    "    # Lambda = ((5**20)*exp(-100*avg))/(((1/avg)**20)*exp(-20*5*avg))\n",
    "    test_statistic = 2*(n*log(1/avg) -n -n*log(3)+3*sum(sample))\n",
    "    # print(\"Test Statistic\",test_statistic)\n",
    "    p_value = 1-stats.chi2.cdf(test_statistic,1)\n",
    "    if test_statistic >= crit:\n",
    "        count += 1\n",
    "print(\"Percentage of times we (correctly) reject the null:\",(count/iterations)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. What do you expect to happen to power? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of times we (correctly) reject the null: 98.48 %\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "count = 0\n",
    "n=50\n",
    "#np.random.seed = 2020\n",
    "for i in range(iterations):\n",
    "    sample = np.random.choice(my_data,50)\n",
    "    avg = np.average(sample)\n",
    "    # Lambda = ((5**50)*exp(-5*50*avg))/(((1/avg)**50)*-exp(-50*(1/avg)))\n",
    "    test_statistic = 2*(n*log(1/avg) -n -n*log(3)+3*sum(sample))\n",
    "    # print(\"Test Statistic\",test_statistic)\n",
    "    p_value = 1-stats.chi2.cdf(test_statistic,1)\n",
    "    if test_statistic >= crit:\n",
    "        count += 1\n",
    "print(\"Percentage of times we (correctly) reject the null:\",(count/iterations)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Different Test\n",
    "\n",
    "We've explored hypothesis tests in this class before. Taking advantage of our computing power, we don't have to rely on test statistics with asymptotic distributions. Let's conduct a more direct hypothesis test using simulation. Recall:\n",
    "\n",
    "$$\n",
    "H_0: \\lambda = 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_1: \\lambda \\neq 3\n",
    "$$\n",
    "\n",
    "Pick a different test statistic. Obtain an empirical distribution of that test statistic under $H_0$. Next, find the $p$-value by determining how often this test statistic is at or further away from the test statistic derived from the sample. Remember that this is a two-sided test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the $p$-value compare to the LRT $p$-value? I wonder how the power of this test compares to our LRT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Let's figure out the power of this test. First, determine for what values of the test statistic would lead us to reject $H_0$. These values can be referred to as your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, determine the power of this test. Like in the LRT case, obtain a sample of size 20 and obtain the test statistic. Repeat many times and see how often your test statistic is in your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. Note that you will have to obtain new critical values in order to do this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
